import pandas as pd
from simple_salesforce import Salesforce
from dotenv import load_dotenv
import os
import json
import numpy as np

# ğŸ” NaÄtenÃ­ pÅ™ihlaÅ¡ovacÃ­ch ÃºdajÅ¯
load_dotenv("credentials.env")

sf = Salesforce(
    username=os.getenv("SF_USERNAME"),
    password=os.getenv("SF_PASSWORD"),
    security_token=os.getenv("SF_TOKEN"),
    domain=os.getenv("SF_DOMAIN", "login")
)

print("âœ… PÅ™ipojeno k Salesforce.")

# ğŸ“¥ NaÄtenÃ­ Excelu
df = pd.read_excel("accounts 28.3..xlsx")

# âœ… PÅ™ejmenovÃ¡nÃ­ sloupcÅ¯ (custom field mapping + billing adresa)
df = df.rename(columns={
    "E-mail": "E_mail__c",
    "PartnerWeb Org ID": "PartnerWeb_ORG_ID__c",
    "Helios ID": "Helios_ID__c",
    "Name": "Name",
    "Phone": "Phone",
    "Blocked": "Blocked__c",
    "Blocked at": "Blocked_on_date__c",
    "Created at last invoice": "Last_jnvoice_date__c",
    "Currency": "Currency__c",
    "State": "State__c",
    "Verified": "Verified__c",
    "Street address": "BillingStreet",
    "ZIP": "BillingPostalCode",
    "City": "BillingCity",
    "Country": "BillingCountry"
})

# âœ… Duplikace adresy pro Shipping
df["ShippingStreet"] = df["BillingStreet"]
df["ShippingPostalCode"] = df["BillingPostalCode"]
df["ShippingCity"] = df["BillingCity"]
df["ShippingCountry"] = df["BillingCountry"]

# âœ… OdstranÄ›nÃ­ NaN a pÅ™evod na string
df = df.fillna("").infer_objects(copy=False)
for col in df.columns:
    df[col] = df[col].astype(str)

# âœ… ÄŒiÅ¡tÄ›nÃ­ adres â€“ odstranÄ›nÃ­ nebezpeÄnÃ½ch znakÅ¯
for col in ["BillingStreet", "BillingCity", "ShippingStreet", "ShippingCity"]:
    df[col] = df[col].str.replace(r'[\"\\]', '', regex=True)

# âœ… OdstranÄ›nÃ­ novÃ½ch Å™Ã¡dkÅ¯ z polÃ­
df["Name"] = df["Name"].str.replace(r'[\r\n\t]', ' ', regex=True)
df["BillingStreet"] = df["BillingStreet"].str.replace(r'[\r\n\t]', ' ', regex=True)

# âœ… ÄŒiÅ¡tÄ›nÃ­ telefonnÃ­ch ÄÃ­sel â€“ odstranÄ›nÃ­ mezer
df["Phone"] = df["Phone"].str.replace(" ", "")

# âœ… PÅ™evod Blocked__c a Verified__c na boolean
df["Blocked__c"] = df["Blocked__c"].apply(lambda x: True if x in ["1", "true", "True"] else False)
df["Verified__c"] = df["Verified__c"].apply(lambda x: True if x in ["1", "true", "True"] else False)

# ğŸ”¢ GenerovÃ¡nÃ­ Import_ID__c
IMPORT_ID_PREFIX = "ACC"
df = df.reset_index(drop=True)
df["Import_ID__c"] = df.index.map(lambda i: f"{IMPORT_ID_PREFIX}{str(i + 1).zfill(4)}")

# âœ… NahrazenÃ­ NaN, inf, -inf, a 'nan' stringÅ¯ hodnotou None
df = df.replace([np.nan, float("inf"), float("-inf"), "nan", "NaN"], None)

# âœ… PÅ™evod date polÃ­ na sprÃ¡vnÃ½ formÃ¡t YYYY-MM-DD nebo None
date_fields = ["Last_jnvoice_date__c", "Blocked_on_date__c"]
for field in date_fields:
    df[field] = pd.to_datetime(df[field], errors="coerce").dt.strftime("%Y-%m-%d")
    df[field] = df[field].replace("NaT", None)

# ğŸ“¤ PÅ™Ã­prava zÃ¡znamÅ¯
records = df[[
    "Name",
    "Phone",
    "E_mail__c",
    "BillingStreet",
    "BillingPostalCode",
    "BillingCity",
    "BillingCountry",
    "ShippingStreet",
    "ShippingPostalCode",
    "ShippingCity",
    "ShippingCountry",
    "Blocked__c",
    "Blocked_on_date__c",
    "Last_jnvoice_date__c",
    "Currency__c",
    "State__c",
    "Verified__c",
    "PartnerWeb_ORG_ID__c",
    "Helios_ID__c",
    "Import_ID__c"
]].to_dict(orient="records")

# âœ… ÄŒiÅ¡tÄ›nÃ­ NaN/inf/None hodnot po pÅ™evodu z DataFrame
def sanitize_record_values(rec):
    for key, value in rec.items():
        if isinstance(value, float):
            if np.isnan(value) or np.isinf(value):
                rec[key] = None
    return rec

records = [sanitize_record_values(rec) for rec in records]

# ğŸ’¾ UloÅ¾enÃ­ vÅ¡ech zÃ¡znamÅ¯ do souboru pro analÃ½zu
with open("debug_records.json", "w", encoding="utf-8") as f:
    json.dump(records, f, indent=2, ensure_ascii=False)
print("ğŸ’¾ UloÅ¾eno do debug_records.json")

print("\nğŸ” Kontrola serializovatelnosti vÅ¡ech zÃ¡znamÅ¯...")
invalid_records = []

for i, record in enumerate(records):
    try:
        json.dumps(record)
    except Exception as e:
        invalid_records.append((i, record, str(e)))

if invalid_records:
    print(f"\nâŒ Nalezeno {len(invalid_records)} nenaserializovatelnÃ½ch zÃ¡znamÅ¯!")
    for i, (index, rec, err) in enumerate(invalid_records[:10]):
        print(f"\nâŒ ChybnÃ½ zÃ¡znam Ä. {index}")
        print(json.dumps(rec, indent=2, ensure_ascii=False))
        print("ğŸ“› Chyba:", err)
else:
    print("âœ… VÅ¡echny zÃ¡znamy jsou serializovatelnÃ©.")
# ğŸ”„ Upsert vÅ¡ech zÃ¡znamÅ¯ pÅ™es BULK API
records = json.loads(json.dumps(records, default=str))
response = sf.bulk.Account.upsert(records, external_id_field='Import_ID__c')

# ğŸ“Š VyhodnocenÃ­ vÃ½sledkÅ¯
success_count = sum(1 for r in response if r.get("success"))
update_count = sum(1 for r in response if r.get("success") and not r.get("created"))
failures = [r for r in response if not r.get("success")]

print(f"\nâœ… ÃšspÄ›Å¡nÄ› nahrÃ¡no: {success_count}")
print(f"ğŸ” Z toho aktualizovÃ¡no: {update_count}")
print(f"âŒ Selhalo: {len(failures)}")

# ğŸ§© ZpÄ›tnÃ© mapovÃ¡nÃ­ chyb na pÅ¯vodnÃ­ Å™Ã¡dky v DataFrame
for i, fail in enumerate(failures[:10]):
    print(f"\nâŒ Chyba Ä. {i+1}")
    print("  ID:", fail.get('id'))
    print("  Success:", fail.get('success'))
    print("  Errors:", fail.get('errors'))
    # Vyhledej pÅ¯vodnÃ­ zÃ¡znam z DataFrame podle Import_ID__c
    failed_import_id = fail.get('record', {}).get('Import_ID__c')
    if failed_import_id:
        original_row = df[df['Import_ID__c'] == failed_import_id]
        if not original_row.empty:
            print("ğŸ§¾ PÅ¯vodnÃ­ Å™Ã¡dek v DataFrame:")
            print(original_row.to_string(index=False))

# ğŸ“ UloÅ¾enÃ­ chyb do CSV pro analÃ½zu
print("\nğŸ“ UklÃ¡dÃ¡m chyby do souboru accounts_import_errors.csv...")
error_rows = []

for i, fail in enumerate(failures):
    failed_index = i  # spÃ¡rovÃ¡nÃ­ podle indexu v pÅ¯vodnÃ­m DataFrame
    error_info = fail.get("errors", [{}])[0]
    original_record = df.iloc[failed_index].to_dict()
    original_record["Chyba_kÃ³d"] = error_info.get("statusCode")
    original_record["Chyba_zprÃ¡va"] = error_info.get("message")
    error_rows.append(original_record)

if error_rows:
    pd.DataFrame(error_rows).to_csv("accounts_import_errors.csv", index=False)
    print("âœ… UloÅ¾eno do accounts_import_errors.csv")
else:
    print("âœ… Å½Ã¡dnÃ© chyby k uloÅ¾enÃ­")

# ğŸ“¤ VÃ½stupnÃ­ CSV s importovanÃ½mi zÃ¡znamy (pro mapovÃ¡nÃ­ napÅ™. kontaktÅ¯)
print("\nğŸ“¦ Generuji vÃ½stupnÃ­ CSV se Salesforce ID...")
query_fields = ["Id", "Name", "Import_ID__c", "Helios_ID__c", "PartnerWeb_ORG_ID__c"]
query = f"SELECT {', '.join(query_fields)} FROM Account WHERE Import_ID__c != NULL"
results = sf.query_all(query)["records"]

# VyÄistÃ­me zÃ¡znamy (odstranÃ­me Salesforce atributy)
export_data = [{k: r.get(k) for k in query_fields} for r in results]

# UloÅ¾Ã­me do CSV
export_df = pd.DataFrame(export_data)
export_df.to_csv("accounts_imported_out.csv", index=False)
print("âœ… UloÅ¾eno do accounts_imported_out.csv")