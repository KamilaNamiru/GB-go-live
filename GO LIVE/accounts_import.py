import pandas as pd
from simple_salesforce import Salesforce
from dotenv import load_dotenv
import os
import json
import numpy as np

# ğŸ” NaÄtenÃ­ pÅ™ihlaÅ¡ovacÃ­ch ÃºdajÅ¯
load_dotenv("credentials.env")

sf = Salesforce(
    username=os.getenv("SF_USERNAME"),
    password=os.getenv("SF_PASSWORD"),
    security_token=os.getenv("SF_TOKEN"),
    domain=os.getenv("SF_DOMAIN", "login")
)

print("âœ… PÅ™ipojeno k Salesforce.")

# ğŸ“¥ NaÄtenÃ­ Excelu
df = pd.read_excel("accounts 28.3. .xlsx")

# ğŸ§¹ ÄŒiÅ¡tÄ›nÃ­ hlaviÄky
df.columns = df.iloc[0]
df = df.drop(index=0).reset_index(drop=True)

# âœ… PÅ™ejmenovÃ¡nÃ­ sloupcÅ¯ (custom field mapping + billing adresa)
df = df.rename(columns={
    "E-mail": "E_mail__c",
    "PartnerWeb Org ID": "PartnerWeb_ORG_ID__c",
    "Helios ID": "Helios_ID__c",
    "Name": "Name",
    "Phone": "Phone",
    "Blocked": "Blocked__c",
    "Blocked at": "Blocked_on_date__c",
    "Created at last invoice": "Last_jnvoice_date__c",
    "Currency": "Currency__c",
    "State": "State__c",
    "Verified": "Verified__c",
    "Street address": "BillingStreet",
    "ZIP": "BillingPostalCode",
    "City": "BillingCity",
    "Country": "BillingCountry"
})

# âœ… Duplikace adresy pro Shipping
df["ShippingStreet"] = df["BillingStreet"]
df["ShippingPostalCode"] = df["BillingPostalCode"]
df["ShippingCity"] = df["BillingCity"]
df["ShippingCountry"] = df["BillingCountry"]

# âœ… OdstranÄ›nÃ­ NaN a pÅ™evod na string
df = df.fillna("").infer_objects(copy=False)
for col in df.columns:
    df[col] = df[col].astype(str)

# âœ… ÄŒiÅ¡tÄ›nÃ­ adres â€“ odstranÄ›nÃ­ nebezpeÄnÃ½ch znakÅ¯
for col in ["BillingStreet", "BillingCity", "ShippingStreet", "ShippingCity"]:
    df[col] = df[col].str.replace(r'[\"\\]', '', regex=True)

# âœ… OdstranÄ›nÃ­ novÃ½ch Å™Ã¡dkÅ¯ z polÃ­
df["Name"] = df["Name"].str.replace(r'[\r\n\t]', ' ', regex=True)
df["BillingStreet"] = df["BillingStreet"].str.replace(r'[\r\n\t]', ' ', regex=True)

# âœ… ÄŒiÅ¡tÄ›nÃ­ telefonnÃ­ch ÄÃ­sel â€“ odstranÄ›nÃ­ mezer
df["Phone"] = df["Phone"].str.replace(" ", "")

# âœ… PÅ™evod Blocked__c a Verified__c na boolean
df["Blocked__c"] = df["Blocked__c"].apply(lambda x: True if x in ["1", "true", "True"] else False)
df["Verified__c"] = df["Verified__c"].apply(lambda x: True if x in ["1", "true", "True"] else False)

# ğŸ”¢ GenerovÃ¡nÃ­ Import_ID__c
IMPORT_ID_PREFIX = "ACC"
df = df.reset_index(drop=True)
df["Import_ID__c"] = df.index.map(lambda i: f"{IMPORT_ID_PREFIX}{str(i + 1).zfill(4)}")

# âœ… NahrazenÃ­ NaN, inf, -inf, a 'nan' stringÅ¯ hodnotou None
df = df.replace([np.nan, float("inf"), float("-inf"), "nan", "NaN"], None)

# âœ… PÅ™evod date polÃ­ na sprÃ¡vnÃ½ formÃ¡t YYYY-MM-DD nebo None
date_fields = ["Last_jnvoice_date__c", "Blocked_on_date__c"]
for field in date_fields:
    df[field] = pd.to_datetime(df[field], errors="coerce").dt.strftime("%Y-%m-%d")
    df[field] = df[field].replace("NaT", None)

# ğŸ“¤ PÅ™Ã­prava zÃ¡znamÅ¯
records = df[[
    "Name",
    "Phone",
    "E_mail__c",
    "BillingStreet",
    "BillingPostalCode",
    "BillingCity",
    "BillingCountry",
    "ShippingStreet",
    "ShippingPostalCode",
    "ShippingCity",
    "ShippingCountry",
    "Blocked__c",
    "Blocked_on_date__c",
    "Last_jnvoice_date__c",
    "Currency__c",
    "State__c",
    "Verified__c",
    "PartnerWeb_ORG_ID__c",
    "Helios_ID__c",
    "Import_ID__c"
]].to_dict(orient="records")

# âœ… ÄŒiÅ¡tÄ›nÃ­ NaN/inf/None hodnot po pÅ™evodu z DataFrame
def sanitize_record_values(rec):
    for key, value in rec.items():
        if isinstance(value, float):
            if np.isnan(value) or np.isinf(value):
                rec[key] = None
    return rec

records = [sanitize_record_values(rec) for rec in records]

# ğŸ’¾ UloÅ¾enÃ­ vÅ¡ech zÃ¡znamÅ¯ do souboru pro analÃ½zu
with open("debug_records.json", "w", encoding="utf-8") as f:
    json.dump(records, f, indent=2, ensure_ascii=False)
print("ğŸ’¾ UloÅ¾eno do debug_records.json")

print("\nğŸ” Kontrola serializovatelnosti vÅ¡ech zÃ¡znamÅ¯...")
invalid_records = []

for i, record in enumerate(records):
    try:
        json.dumps(record)
    except Exception as e:
        invalid_records.append((i, record, str(e)))

if invalid_records:
    print(f"\nâŒ Nalezeno {len(invalid_records)} nenaserializovatelnÃ½ch zÃ¡znamÅ¯!")
    for i, (index, rec, err) in enumerate(invalid_records[:10]):
        print(f"\nâŒ ChybnÃ½ zÃ¡znam Ä. {index}")
        print(json.dumps(rec, indent=2, ensure_ascii=False))
        print("ğŸ“› Chyba:", err)
else:
    print("âœ… VÅ¡echny zÃ¡znamy jsou serializovatelnÃ©.")
# ğŸ”„ Upsert vÅ¡ech zÃ¡znamÅ¯ pÅ™es BULK API
records = json.loads(json.dumps(records, default=str))
response = sf.bulk.Account.upsert(records, external_id_field='Import_ID__c')

# ğŸ“Š VyhodnocenÃ­ vÃ½sledkÅ¯
success_count = sum(1 for r in response if r.get("success"))
update_count = sum(1 for r in response if r.get("success") and not r.get("created"))
failures = [r for r in response if not r.get("success")]

print(f"\nâœ… ÃšspÄ›Å¡nÄ› nahrÃ¡no: {success_count}")
print(f"ğŸ” Z toho aktualizovÃ¡no: {update_count}")
print(f"âŒ Selhalo: {len(failures)}")

for i, fail in enumerate(failures[:10]):
    print(f"\nâŒ Chyba Ä. {i+1}")
    print("  ID:", fail.get('id'))
    print("  Success:", fail.get('success'))
    print("  Errors:", fail.get('errors'))